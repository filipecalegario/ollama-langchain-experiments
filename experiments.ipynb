{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.0.349-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.23-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_community-0.0.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-core<0.1,>=0.0.13 (from langchain)\n",
      "  Downloading langchain_core-0.0.13-py3-none-any.whl.metadata (978 bytes)\n",
      "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
      "  Downloading langsmith-0.0.69-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m849.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.5.2-py3-none-any.whl.metadata (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.4-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting anyio<5,>=3 (from langchain-core<0.1,>=0.0.13->langchain)\n",
      "  Downloading anyio-4.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.1,>=0.0.13->langchain) (23.2)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.5 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.14.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3->langchain-core<0.1,>=0.0.13->langchain)\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading langchain-0.0.349-py3-none-any.whl (808 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.6/808.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.1-cp311-cp311-macosx_11_0_arm64.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.8/386.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.0.13-py3-none-any.whl (188 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.2/188.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.2-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.14.5-cp311-cp311-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.5/167.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading SQLAlchemy-2.0.23-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading anyio-4.1.0-py3-none-any.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.0-cp311-cp311-macosx_11_0_arm64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Downloading yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, tenacity, SQLAlchemy, sniffio, PyYAML, pydantic-core, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, idna, frozenlist, charset-normalizer, certifi, attrs, annotated-types, yarl, typing-inspect, requests, pydantic, jsonpatch, anyio, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-community, langchain\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.23 aiohttp-3.9.1 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.1.0 attrs-23.1.0 certifi-2023.11.17 charset-normalizer-3.3.2 dataclasses-json-0.6.3 frozenlist-1.4.0 idna-3.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.349 langchain-community-0.0.1 langchain-core-0.0.13 langsmith-0.0.69 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 numpy-1.26.2 pydantic-2.5.2 pydantic-core-2.14.5 requests-2.31.0 sniffio-1.3.0 tenacity-8.2.3 typing-inspect-0.9.0 urllib3-2.1.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Artificial intelligence (AI) has a rich and varied history that spans several decades. Here is a brief overview of the major milestones in the development of AI:\n",
      "\n",
      "1. 1950s-1960s: The Dartmouth Conference and the Birth of AI\n",
      "The field of AI was founded in 1956 at a conference held at Dartmouth College in Hanover, New Hampshire. Attendees included computer scientists, mathematicians, and cognitive scientists who were interested in exploring the possibilities of creating machines that could simulate human intelligence. This event is often considered the birthplace of AI as a distinct field of research.\n",
      "2. 1950s-1960s: The Development of Rule-Based Systems\n",
      "In the years following the Dartmouth Conference, researchers began developing rule-based systems, which were designed to mimic human reasoning by applying a set of rules to solve problems. These systems were able to perform well on narrowly defined tasks, but struggled with more complex, open-ended problems.\n",
      "3. 1970s-1980s: The Rise of Expert Systems\n",
      "Expert systems were developed in the 1970s and 1980s as a way to simulate the decision-making abilities of human experts in specific domains, such as medical diagnosis or financial planning. These systems used a knowledge base and inference engine to reason about the problem domain and provide recommendations.\n",
      "4. 1980s-1990s: The Emergence of Machine Learning\n",
      "Machine learning was developed in the 1980s and 1990s as a way to enable machines to learn from data, rather than relying on pre-programmed rules. This allowed for more flexible and adaptive AI systems that could improve their performance over time.\n",
      "5. 1990s-2000s: The Development of Deep Learning\n",
      "In the late 1990s and early 2000s, researchers began developing deep learning algorithms, which are capable of learning complex representations of data. These algorithms have been instrumental in achieving state-of-the-art performance in a variety of AI tasks, including image and speech recognition, natural language processing, and game playing.\n",
      "6. 2010s: The Rise of Big Data and Deep Learning\n",
      "In the 2010s, the availability of large amounts of data and the development of powerful computational resources enabled the training of deep learning models on a scale not previously possible. This has led to significant advances in AI applications such as computer vision, natural language processing, and autonomous vehicles.\n",
      "7. Present Day: The Emergence of Reinforcement Learning and Transformers\n",
      "Reinforcement learning is a type of machine learning that involves training agents to make decisions in complex, dynamic environments. This has led to significant advances in areas such as robotics and game playing. Transformers are a type of deep learning algorithm that have been instrumental in achieving state-of-the-art performance in natural language processing tasks such as machine translation and language modeling.\n",
      "\n",
      "Throughout its history, AI has been driven by a combination of scientific curiosity, practical applications, and social concerns. As AI continues to evolve, it is likely to have a growing impact on many aspects of society, from healthcare and education to transportation and employment."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nArtificial intelligence (AI) has a rich and varied history that spans several decades. Here is a brief overview of the major milestones in the development of AI:\\n\\n1. 1950s-1960s: The Dartmouth Conference and the Birth of AI\\nThe field of AI was founded in 1956 at a conference held at Dartmouth College in Hanover, New Hampshire. Attendees included computer scientists, mathematicians, and cognitive scientists who were interested in exploring the possibilities of creating machines that could simulate human intelligence. This event is often considered the birthplace of AI as a distinct field of research.\\n2. 1950s-1960s: The Development of Rule-Based Systems\\nIn the years following the Dartmouth Conference, researchers began developing rule-based systems, which were designed to mimic human reasoning by applying a set of rules to solve problems. These systems were able to perform well on narrowly defined tasks, but struggled with more complex, open-ended problems.\\n3. 1970s-1980s: The Rise of Expert Systems\\nExpert systems were developed in the 1970s and 1980s as a way to simulate the decision-making abilities of human experts in specific domains, such as medical diagnosis or financial planning. These systems used a knowledge base and inference engine to reason about the problem domain and provide recommendations.\\n4. 1980s-1990s: The Emergence of Machine Learning\\nMachine learning was developed in the 1980s and 1990s as a way to enable machines to learn from data, rather than relying on pre-programmed rules. This allowed for more flexible and adaptive AI systems that could improve their performance over time.\\n5. 1990s-2000s: The Development of Deep Learning\\nIn the late 1990s and early 2000s, researchers began developing deep learning algorithms, which are capable of learning complex representations of data. These algorithms have been instrumental in achieving state-of-the-art performance in a variety of AI tasks, including image and speech recognition, natural language processing, and game playing.\\n6. 2010s: The Rise of Big Data and Deep Learning\\nIn the 2010s, the availability of large amounts of data and the development of powerful computational resources enabled the training of deep learning models on a scale not previously possible. This has led to significant advances in AI applications such as computer vision, natural language processing, and autonomous vehicles.\\n7. Present Day: The Emergence of Reinforcement Learning and Transformers\\nReinforcement learning is a type of machine learning that involves training agents to make decisions in complex, dynamic environments. This has led to significant advances in areas such as robotics and game playing. Transformers are a type of deep learning algorithm that have been instrumental in achieving state-of-the-art performance in natural language processing tasks such as machine translation and language modeling.\\n\\nThroughout its history, AI has been driven by a combination of scientific curiosity, practical applications, and social concerns. As AI continues to evolve, it is likely to have a growing impact on many aspects of society, from healthcare and education to transportation and employment.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"llama2\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "llm(\"Tell me about the history of AI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
